# -*- coding: utf-8 -*-
"""LSTM Time Series Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WGoHVfqoqyR_2sSvH0gbXDVjeCl3qNJx
"""

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
import zipfile,os,random,shutil

local_zip = 'archive.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('')

df4 = pd.read_csv("MLTempDataset1.csv")
print(df4)

"""Dataset diambil dari [kaggle](https://www.kaggle.com/datasets/vitthalmadane/ts-temp-1?select=MLTempDataset1.csv)

Dimana dataset diambil pada rentang waktu 4 Januari 2022 hingga 25 Oktober 2022 dan data diambil tiap jam dan temperatur ruangan di rata-rata (Hourly_Temp)
"""

df4.isnull().sum()

time = df4['Datetime'].values
temp  = df4['Hourly_Temp'].values
 
plt.figure(figsize=(25,10))
plt.plot(time, temp)
plt.xticks(np.arange(0, len(time)+1, 96),rotation=90)
plt.title('Temp',
          fontsize=20);

train_size = int((len(temp)*0.8))
test_size = len(temp)-train_size
print("total dataset", len(temp))
print("total data latih",train_size,f"persentase ukuran data training {train_size/len(temp)}")
print("total data validasi",test_size,f"persentase ukuran data testing {test_size/len(temp)}")

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<1.5 and logs.get('val_mae')<1.5):
      print("\nMAE model untuk data latih dan validasi sudah < 1.5!!")
      self.model.stop_training = True
callbacks = myCallback()

"""Callback untuk stop pelatihan model ketika sudah mencapai MAE < 1,5 baik untuk pelatihan dan validasi. 

Metrik MAE < 1,5 dipilih dengan cara menghitung skala data "Hourly_Temp" pada dataset dengan nilai minimum 5,35 dan maksimum 36,5. Dimana 5% dari skala data adalah (36,5-5,35)*0,05 = 1,5575
"""

train_set = windowed_dataset(temp[:train_size], window_size=168, batch_size=196, shuffle_buffer=2000)
test_set = windowed_dataset(temp[train_size:], window_size=168, batch_size=196, shuffle_buffer=2000)
model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(168, return_sequences=True),
  tf.keras.layers.LSTM(168),
  tf.keras.layers.Dense(64, activation="relu"),
  tf.keras.layers.Dense(32, activation="relu"),
  tf.keras.layers.Dense(16, activation="relu"),
  tf.keras.layers.Dense(8, activation="relu"),
  tf.keras.layers.Dense(1),
])

"""Dipilih window sebesar 168, karena data temperatur diambil setiap 1 jam, berarti 1 hari adalah 24 data. Karena window 168 maka, 1 window adalah 168/24 = 7 hari (1 minggu)"""

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
result = model.fit(
    train_set,
    epochs=100,
    validation_data=test_set,
    verbose=2,
    callbacks=[callbacks])

plt.plot(result.history['loss'])
plt.plot(result.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'], loc='upper right')
plt.show()

plt.plot(result.history['mae'])
plt.plot(result.history['val_mae'])
plt.title('Model MAE Metric')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'], loc='lower right')
plt.show()